---
title: SOM神经网络
date: 2015-01-01 11:00:00
categories: fbANNSVM
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<!--<img src="http://latex.codecogs.com/gif.latex? a^{i}"/>
<center><img src="{{ site.baseurl }}/images/pdBase/svm_smo1.png"></center>-->

### 概述

   <strong>self-organizing map，SOM，自组织映射。一种无导师学习的网络，基于竞争学习，主要用于对输入向量进行区域分类，和自组织竞争网络不同的是，它不但识别输入区域临近的区域，还关注输入向量的分布特性和拓扑结构。<strong>


   在竞争学习过程中，神经元变化依不同输入模式（刺激）或者输入模式的类别而选择性地调整。这样调整后神经元的位置彼此之间成为有序的，使得对于不同的输入特征，在网络上建立起有意义的坐标系。在拓扑映射中输出神经元的空间位置对应于特殊的定义域或从输入空间抽取数据的特征。SOM的主要目的是将任意维数的输入信号模式转变为一维或二维的离散映射，并且以拓扑有序的方式自适应实现这个变换。

   Kohonen的SOM算法的本质是用一个简单的几何计算代替类Hebb规则的复杂性质和侧向相互作用。算法的主要构成参数有：1）根据一定概率分布产生激活模式的连续输入空间。2）以神经元的网络形式表示一个拓扑结构，它定义一个离散输出空间。（3）在获胜神经元i(x)周围定义随时间变化的领域函数<img src="http://latex.codecogs.com/gif.latex? h_{j,i(x)} (n)"/> 。 （4）学习率参数<img src="http://latex.codecogs.com/gif.latex? \eta (x)"/>以一初始值开始，然后随着时间n递减，但永不为零。

<center><img src="{{ site.baseurl }}/images/pdBase/ann_som1.png"></center>

---

SOM的特点：

1. 输入空间近似； 
2. 拓扑排序；
3. 密度匹配：特征映射反映输入分布在统计上的变化：在输入空间中样本向量x以高的概率抽取的区域映射到输出空间的更大区域，从而比在输入空间中向量x以低的概率抽取的区域有更好的分辨率。但由于SOM算法计算的特征映射往往趋向于过高表示低输入密度区域和过低表示高输入密度区域，即SOM算法不能为输入数据固有的概率分布提供可信赖的表示。
4. 特征选择：从输入空间中给定数据，自组织映射能够为逼近固有分布选择一组最好的特征。

---

优点：

1. 对输入模式的自动聚类作用； 
2. 网络结构简单，具有很好的生物神经元特征；
3. 容错率；
4. 具有特征映射的能力；
5. 具有可视化；
6. 具有自稳定性；
7. 输出的排序性；
8. 具有自联想性；

---

缺点：

1. 聚类数目和初始网络结构固定，需要用户预先指定聚类数目和初始的权值矩阵；
2. 可能会出现一些始终不能获胜的神经元和一些因为经常胜利被过度利用的神经元，不能充分利用所有神经元信息而将导致影响聚类质量；
3. 要想往SOM网络中加入新的类别必须先完整的重新学习之后方可进行；
4. 数据的输入顺序会影响甚至决定了输出结果，数量少时尤为明显； 
5. 连接权值初始化、计算策略、参数选择不当时会导致网络收敛时间过长，甚至难以达到收敛状态。



