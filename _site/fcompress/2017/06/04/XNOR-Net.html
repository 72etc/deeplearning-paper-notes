<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>XNOR-Net（2017）</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="计算机视觉算法学习笔记">
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/hc.css" rel="stylesheet">
<link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
<!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif] d-->

  </head>
  <body>
    <div class="nav-toggle"><i class="fa fa-bars fa-2x"></i> ChenJM </div>
    <div id = "wrapper">
      <div class="navbar navbar-default" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <p class="navbar-brand">cjmcv</p>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
      <!--<li><a href="/list.html">List</a></li>-->
      <!--<li><a href="/links.html">Links</a></li>-->
      <!--<li><a href="/projects.html">Algorithms</a></li>-->
      <!--<li><a href="/programs.html">Programs</a></li>-->
      <!--<li><a href="/about.html">About Me</a></li>-->
      <li><a href="/projects.html">论文阅读(2015--)</a></li>
      <li><a href="/bprojects.html">基础算法(2013-2015)</a></li>
      <li><a href="/about.html">个人简历</a></li>
      <li><a href="/statement.html">版权声明</a></li>
      <li><a href="https://github.com/cjmcv"> <font color="#00BFFF"> Github Site </font></a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>

<!-- Sidebar -->
<div id="sidebar-wrapper">
  <ul class="sidebar-nav">
    <li class="sidebar-brand"><a href="/"><h1 class="brand">cjmcv</h1></a><h3>计算机视觉算法学习笔记</h3></li>

    <div>
      <center><img src="/images/me.jpg" height="195" width="180"></center>
    </div>
 
    <hr />
    <li><a href="/projects.html">论文阅读(2015--)</a></li>
    <li><a href="/bprojects.html">基础算法(2013-2015)</a></li>
    <li><a href="/about.html">个人简历</a></li>
    <li><a href="/statement.html">版权声明</a></li>
    <li><a href="https://github.com/cjmcv"> <font color="#00BFFF"> Github Site </font></a></li>
    <hr />


    <div>
      <center><img src="/images/weixin.jpg" height="130" width="130"></center>
    </div>
    <!--
    <div id="social-wrapper">
      <li> <a href=""><i class="fa fa-twitter-square"></i> @twitter</a></li>
      <li> <a href=""><i class="fa fa-linkedin-square"></i> linkedin</a> </li>
      <li> <a href=""><i class="fa fa-facebook-square"></i> facebook</a></li>
      <li> <a href=""><i class="fa fa-github-square"></i> github</a> </li>
    </div>
    -->
  </ul>
</div>

      <div class="container">
        <div id="article">
  <div class="article-title">XNOR-Net（2017）</div>
  <p class="meta">
    <small>
      &nbsp;<i class="fa fa-calendar-o"></i> 04 Jun 2017
    </small>
  </p> <hr/>
  <div class="post">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>论文： Rastegari M, Ordonez V, Redmon J, et al. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks[J]. 2016:525-542.</p>

<p>Github: <a href="https://github.com/allenai/XNOR-Net">https://github.com/allenai/XNOR-Net</a></p>

<h3 id="section">论文算法概述</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>   在论文中以加快运算速度为目的，牺牲少许准确率为代价，提出了两个简化网络：Binary-Weight-Networks 和XNOR-Networks。其中Binary-Weight-Networks中，滤波器参数被二值化，节省了32倍的内存空间。在XNOR-Networks中，滤波器和卷积层的输入都被二值化。其中XNOR-Networks的卷积操作以根本上的二值操作进行近似，使其比普通的卷积操作快58倍并节省32倍内存。
</code></pre>
</div>

<center><img src="/images/pdCompress/xnornet1.png" /></center>

<h3 id="binary-convolutional-neural-network">Binary Convolutional Neural Network</h3>

<p>以一个三元组&lt;I_,W_,<em>&gt;表示一个L层的CNN结构，I_为一个张量集，每个元素是CNN网络上对应层的输入张量（如图1中绿色立方体）。W_也是一个张量集，每个元素表示网络中某一层的某个滤波器的权重，</em>表示卷积操作。Binary-weights中W_为二值化张量，XNOR-Networks中I_和W_都是二值化张量。</p>

<h3 id="binary-weight-networks">Binary-Weight-Networks</h3>

<p>为约束卷积网络&lt;I_,W_,*&gt;有二值化的权重参数，这里使用（-1，+1）的二值化模板B和一个缩放因子a来估计实数的权重参数，即W约等于aB，一个卷积操作可以近似为：<img src="/images/pdCompress/xnornet2.png" />,其中I和B之间的符号表示没有乘法操作的卷积运算。由于权重是二值化的，所以可以使用加和减来完成卷积运算。这二值化的权重相对于单精度的来说，内存消耗减少了32倍。</p>

<p><strong>Estimating binary weights：</strong>没有的广义上的loss，为了给W约等于aB找到一个最佳的估计，解决一下的优化过程：</p>

<center><img src="/images/pdCompress/xnornet3.png" /></center>

<p><strong>Training Binary-Weights-Networks：</strong>训练CNN过程的每次迭代都涉及前向/反向传播和权重更新三步。在训练带有二值化卷积权重的CNN时，只需要在前向和反向传播过程中将权重进行二值化。为计算sign函数sign(r)的梯度，采用Binarynet论文中提到的方法，即有<img src="/images/pdCompress/xnornet4.png" />，在反向传播中，scaled sign函数的梯度为<img src="/images/pdCompress/xnornet5.png" />。为更新参数，使用高精度（实数）的权重。因为在梯度下降时，参数变化很小，在更新完参数后的二值化会忽略这些改变，影响训练。</p>

<p>下图展示训练带二值化权重的CNN网络的过程。首先，通过计算B和A（上面提到的二值化模板和缩放因子的张量）将每层网络的权重滤波器二值化。然后使用二值化权重和其对应的缩放因子进行前向传播，所有的卷积操作都如公式（1）所示。然后进行反向传播，其中的梯度都由估计的权重滤波器计算得到。最后以一些更新规则（如SGD或ADAM等）更新权重参数。当训练结果后，则不需要保留实数的权重，因为在推断过程中只需要以二值化权重的基础上进行前向传播。</p>

<center><img src="/images/pdCompress/xnornet6.png" /></center>

<h3 id="xnor-networks">XNOR-Networks</h3>

<p>前面的内容中，我们尝试找到二值化权重和缩放因子去近似实数权重，而卷积层的输入仍然是实数的张量。这里开始解释如果把权重和输入都做二值化，这样卷积操作可以通过XNOR和bitcounting来高效的实现。一个卷积包含重复的移动和点积操作，移动操作将权重滤波器在输入中移动，而点积则在权重滤波器和输入的对应部分进行像素级的乘法运算。如果将点积运算用二值化操作来实现，那么卷积就可以被近似为使用二值化操作来实现了。在两个二值化向量之间的点积运算可以用XNOR-Bitcounting（论文BinaryNet中提出）来实现。</p>

<p><strong>Binary Dot Product：</strong></p>

<center><img src="/images/pdCompress/xnornet7.png" /></center>

<p><strong>Binary Convolution：</strong>卷积滤波器W和输入张量I，需要计算输入张量I中对应W大小的所有可能的子张量的缩放因子beta。其中两个子张量如图2中X1和X2所示。由于子张量之间的重叠，计算所有可能的子张量的beta的计算量很大，为减小这个计算负担，首先需要计算一个矩阵<img src="/images/pdCompress/xnornet8.png" />，这是输入I的所有通道元素的绝对值均值，然后用一个2D滤波器k与A卷积，K = A * k，K包含用于I的所有子张量的缩放因子beta，K_ij对应于所有以位置(i,j)为中心的子张量的beta。这个过程如图2第3行所示。当获得W的缩放因子alpha和子张量的缩放因子beta（以K表示）后，可以用以下二值化操作来近似输入I和权重W之间的卷积运算：<img src="/images/pdCompress/xnornet9.png" />。其中圈内加*，表示使用XNOR和bitcount操作的卷积运算。如图2最后一行所示。</p>

<center><img src="/images/pdCompress/xnornet10.png" /></center>

<p><strong>Training XNOR-Networks：</strong>CNN的一个典型的block包含几个网络层，如图3左所示，该block有4层，1-Convolutional，2-Batch Normalization，3-Activation，4-Pooling。在二值化输入中采用池化操作会导致信息的大量丢失，因此这里将池化操作放到卷积后面。为更大程度上减少二值化导致的信息丢失，作者将输入在进行二值化之前做了归一化，这样保证了数据具有0均值，使以0作为二值化阈值时的量化误差更小。Block的结构如图3右所示。这二值化激活层（BinActiv）计算了K和sign(I)，下一层（BinConv）在给定K和sign(I)的情况下，通过公式(11)计算二值化卷积。然后最后一层进行池化。训练过程与上面的algorithm 1一样。</p>

<center><img src="/images/pdCompress/xnornet11.png" /></center>

<p><strong>Binary Gradient：</strong>这计算瓶颈在于在每一层的方向传播中计算权重W和输入的梯度(gin)之间的卷积。与前向计算的二值化类似，我们可以将反向传播的gin二值化。这样会是训练过程变得很高效。需要注意的是，如果我们使用公式（6）去计算gin的缩放因子，那么SGD中，最大变幅（maximum change）的方向会被削弱。为在每个维度上保留这最大变化，作者采用<img src="/images/pdCompress/xnornet12.png" />作为缩放因子。</p>

<p><strong>k-bit Quantization:：</strong>论文到这里为止，展示的都是采用sign函数的权重和输入的1-bit量化。但也可以使用<img src="/images/pdCompress/xnornet13.png" />代替sign函数，很容易地将量化等级扩展到k-bits，式子中[.]表示取整操作，且x在[-1,1]之间。</p>

<h3 id="experiments">Experiments</h3>

<center><img src="/images/pdCompress/xnornet14.png" /></center>

<center><img src="/images/pdCompress/xnornet15.png" /></center>

<center><img src="/images/pdCompress/xnornet16.png" /></center>

  </div>
</div>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!--<a href="https://twitter.com/share" class="twitter-share-button " data-size="small" data-count="none">Tweet</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
-->
<ul class="pager">

  <li class="previous"><a href="/fcompress/2017/06/02/BinaryNet.html">&larr; Older</a></li>


  <li class="next"><a href="/fcompress/2017/08/13/SqueezeNet.html">Newer &rarr;</a></li>

</ul>

<!--<div id="disqus_thread">

  <script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'diqus-username'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>
    Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>

  <a href="http://disqus.com" class="dsq-brlink">
    comments powered by <span class="logo-disqus">Disqus</span>
  </a>

</div>
-->

      </div>
      <div class="container">
  <footer>
    <p class="text-muted credit">
      <center>
      &copy; 2017 cjmcv &middot;
      <a href="https://github.com/cjmcv"> Github Site </a>
      2017-11-18 16:37:06 +0800
      </center>
    </p>
  </footer>
</div>

    </div>
    <!-- Bootstrap core JavaScript-->
<script src="/js/jquery-1.10.2.min.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/hc.js"></script>

  </body>
</html>
