<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>深度学习基本概念</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="计算机视觉算法学习笔记">
<link href="/css/bootstrap.min.css" rel="stylesheet">
<link href="/css/hc.css" rel="stylesheet">
<link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
<!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
  <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif] d-->

  </head>
  <body>
    <div class="nav-toggle"><i class="fa fa-bars fa-2x"></i> ChenJM </div>
    <div id = "wrapper">
      <div class="navbar navbar-default" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <p class="navbar-brand">陈健明</p>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
      <!--<li><a href="/list.html">List</a></li>-->
      <!--<li><a href="/links.html">Links</a></li>-->
      <li><a href="/projects.html">Algorithms</a></li>
      <li><a href="/programs.html">Programs</a></li>
      <li><a href="/about.html">About Me</a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>

<!-- Sidebar -->
<div id="sidebar-wrapper">
  <ul class="sidebar-nav">
    <li class="sidebar-brand"><a href="/"><h1 class="brand">陈健明</h1></a><h3>计算机视觉算法学习笔记</h3></li>

    <div>
      <center><img src="/images/me.jpg" height="195" width="180"></center>
    </div>
 
    <hr />
    <li><a href="/projects.html">论文阅读</a></li>
    <li><a href="/bprojects.html">基础算法</a></li>
    <li><a href="/programs.html">开源码学习</a></li>
    <li><a href="/about.html">关于</a></li>
    <hr />

    
    <div>
      <center><img src="/images/weixin.jpg" height="130" width="130"></center>
    </div>
    <!--
    <div id="social-wrapper">
      <li> <a href=""><i class="fa fa-twitter-square"></i> @twitter</a></li>
      <li> <a href=""><i class="fa fa-linkedin-square"></i> linkedin</a> </li>
      <li> <a href=""><i class="fa fa-facebook-square"></i> facebook</a></li>
      <li> <a href=""><i class="fa fa-github-square"></i> github</a> </li>
    </div>
    -->
  </ul>
</div>

      <div class="container">
        <div id="article">
  <div class="article-title">深度学习基本概念</div>
  <p class="meta">
    <small>
      &nbsp;<i class="fa fa-calendar-o"></i> 01 Jan 2015
    </small>
  </p> <hr/>
  <div class="post">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<!--<img src="http://latex.codecogs.com/gif.latex? a^{i}"/>
<center><img src="/images/pdBase/svm_smo1.png"></center>-->

<h3 id="section">概述</h3>

<p>一种基于无监督特征学习和特征层次结构的学习方法。</p>

<p><strong>本质：</strong>通过构建多隐层的模型和海量训练数据（可为无标签数据），来学习更有用的特征，从而最终提升分类或预测的准确性。 “深度模型”是手段，“特征学习”是目的。</p>

<h3 id="section-1">与浅层学习区别</h3>

<ol>
  <li>
    <p>强调了模型结构的深度，通常有5-10多层的隐层节点；</p>
  </li>
  <li>
    <p>明确突出了特征学习的重要性，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。</p>
  </li>
</ol>

<h3 id="dnn">深度神经网络DNN分以下三类：</h3>

<ol>
  <li>
    <p>前馈深度网络(feed-forward deep networks，FFDN)，由多个编码器层叠加而成,如多层感知机(multi-layer perceptrons, MLP) 、卷积神经网络(convolutional neural networks, CNN)等。</p>
  </li>
  <li>
    <p>反馈深度网络( feed-back deep networks,FBDN)，由多个解码器层叠加而成，如反卷积网络(deconvolutional networks,，DN)、层次稀疏编码网络(hierarchical sparse coding,，HSC)等。</p>
  </li>
  <li>
    <p>双向深度网络(bi-directional deep networks,BDDN)，通过叠加多个编码器层和解码器层构成(每层可能是单独的编码过程或解码过程，也可能既包含编码过程也包含解码过程)，如深度玻尔兹曼机(deep Boltzmann machines,DBM)、深度信念网络(deep belief networks,DBN)、栈式自编码器(stacked auto-encoders,SAE)等。</p>
  </li>
</ol>

<h3 id="bp">传统神经网络的训练方法为什么不能用在深度神经网络（因为BP算法存在的问题）</h3>

<ol>
  <li>
    <p>在反向传播时梯度越来越稀疏：从顶层越往下，误差校正信号越来越小，当层数较多时，梯度甚至会消失。即会出现梯度弥散（diffusion of gradients）的现象。</p>
  </li>
  <li>
    <p>梯度下降的优化过程就变成非凸优化，比较容易陷入局部极值：尤其是从远离最优区域开始的时候（随机值初始化会导致这种情况的发生）；</p>
  </li>
  <li>
    <p>一般，我们只能用有标签的数据来训练：但大部分的数据是没标签的，DNN待学习的参数非常的多（Andrew Ng在Google搞的那个有1.15billion个参数），数据不足会导致严重的过拟合现象；</p>
  </li>
</ol>

<h3 id="wake-sleephinton2006-">深度神经网络（多层的神经网络）一种训练过程（逐层训练的方式，wake-sleep由hinton在2006年提出, 现在一般不用）</h3>

<p><strong>第一步：采用自下而上的无监督学习（相当于BP神经网络中的权值初始化）</strong></p>

<ol>
  <li>
    <p>逐层构建单层神经元。</p>
  </li>
  <li>
    <p>当所有层训练完后，每层采用wake-sleep算法进行调优。每次仅调整一层，逐层调整。这个过程可以看作是一个feature learning的过程，是和传统神经网络区别最大的部分。wake-sleep算法包含wake阶段和sleep阶段：</p>
  </li>
</ol>

<ul>
  <li>
    <p>wake阶段：认知过程，通过下层的输入特征（Input）和向上的认知（Encoder）权重产生每一层的抽象表示（Code），再通过当前的生成（Decoder）权重产生一个重建信息（Reconstruction），计算输入特征和重建信息残差，使用梯度下降修改层间的下行生成（Decoder）权重。也就是“如果现实跟我想象的不一样，改变我的生成权重使得我想象的东西变得与现实一样”。</p>
  </li>
  <li>
    <p>sleep阶段：生成过程，通过上层概念（Code）和向下的生成（Decoder）权重，生成下层的状态，再利用认知（Encoder）权重产生一个抽象景象。利用初始上层概念和新建抽象景象的残差，利用梯度下降修改层间向上的认知（Encoder）权重。也就是“如果梦中的景象不是我脑中的相应概念，改变我的认知权重使得这种景象在我看来就是这个概念”。</p>
  </li>
</ul>

<hr />

<p><strong>第二步：自顶向下的监督学习（用wake-sleep + 梯度下降法逐层分别各自调整，而不是用BP一直往回传）</strong></p>

<p>这一步是在第一步学习获得各层参数进的基础上，在最顶的编码层添加一个分类器（例如罗杰斯特回归、SVM等），而后通过带标签数据的监督学习，利用梯度下降法去微调整个网络参数。</p>

<p>深度学习的第一步实质上是一个网络参数初始化过程。区别于传统神经网络初值随机初始化，深度学习模型是通过无监督学习输入数据的结构得到的，因而这个初值更接近全局最优，从而能够取得更好的效果。</p>

<hr />

<p>好处：可通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表示。</p>

<p>难题（缺点）：</p>

<ol>
  <li>
    <p>深度神经网络模型复杂，训练数据多，计算量大。</p>
  </li>
  <li>
    <p>深度神经网络训练收敛难，需要反复多次实验。深度神经网络是非线性模型，其代价函数是非凸函数，容易收敛到局部最优解。</p>
  </li>
  <li>
    <p>深度神经网络的模型结构、输入数据处理方式、权重初始化方案、参数配置、激活函数选择、权重优化方法等均可能对最终效果有较大影响。</p>
  </li>
  <li>
    <p>深度神经网络的数学基础研究稍显不足。虽然可以通过限制性波尔兹曼机（Restricted Boltzmann Machines，RBMs）等减少陷入局部最优的风险，但仍然不是彻底的解决方案。</p>
  </li>
</ol>

<center><img src="/images/pdBase/dnn_b1.png" /></center>


  </div>
</div>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!--<a href="https://twitter.com/share" class="twitter-share-button " data-size="small" data-count="none">Tweet</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
-->
<ul class="pager">

  <li class="previous"><a href="/fbdnn/2015/01/01/DNN_TRICK.html">&larr; Older</a></li>


  <li class="next"><a href="/fbopt/2015/01/01/OPT_PSO.html">Newer &rarr;</a></li>

</ul>

<!--<div id="disqus_thread">

  <script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'diqus-username'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>
    Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>

  <a href="http://disqus.com" class="dsq-brlink">
    comments powered by <span class="logo-disqus">Disqus</span>
  </a>

</div>
-->

      </div>
      <div class="container">
  <footer>
    <p class="text-muted credit">
      <center>
      &copy; 2017 陈健明 &middot;
      <a href="https://github.com/cjmcv"> Github Site </a>
      2017-02-05 00:29:37 +0800
      </center>
    </p>
  </footer>
</div>

    </div>
    <!-- Bootstrap core JavaScript-->
<script src="/js/jquery-1.10.2.min.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/hc.js"></script>

  </body>
</html>
